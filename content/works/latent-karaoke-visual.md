---
title: "holarchy: movie clip selection using multi-modal representation"
date: 2020-05-02T12:24:29+09:00
---

{{< figure src="https://user-images.githubusercontent.com/20740529/82110712-6cc76580-977b-11ea-9097-63b41d78f70c.png" title="Generative Model" class="center" width="320" >}}
https://ai-visual.github.io/holarchy

本作品はディープラーニングを用いた映像の自動選択により，新たなaudio-visualを作り出すオンラインインスタレーションである．


これまでaudio-visual，DJ+VJなどの音と映像が共存する表現領域における映像表現は，すでに存在するクリップを組み合わせることによるサンプリング的手法，リアルタイムにコンピュータで計算されるジェネラティブな手法，目の前で起こる現象の音とその状況自体を見せること，など様々なアプローチが行われてきた．その視覚的な効果によって音楽の拡張や，新たな意味の付与などのがなされてきた．


しかしどの手法においても，送出する映像やプログラムの選択自体はアーティストの恣意的な判断によって曲に対応させることが前提であった．


本作品は曲の特徴量と作者が事前に選択した多数の映像の特徴量を同空間で比較し，自動的に選択することで新たなaudio-visual作品を作り出す，アーティストによる恣意性を廃したオンラインインスタレーションである．作品では鑑賞者が選択したyoutube動画の音が，数秒ごとに区切られ，その特徴量と，事前に準備された無数の映画や映像の短く区切られたクリップの特徴量を同空間で比較して最も近い映像を選び出し，音楽とともにそれにフィットした映像を次々表示する．
この映像選択手法によって，アーティストがこれまで構築してきた音に対する映像のマッピング関係をディープラーニングによって再構築し，あり得るかもしれない対応関係の可能性を示唆する．また，これまで繋がり得なかった異なる映画・映像の繋がりのないシーンが一つの映像となり，総体として立ち現れる（部分であり全体であること，holarchy）ことで，鑑賞者はそれらの関連性から一つのストーリーを見出すことになる．
本作品によって，audio-visualやDJ+VJ表現は一度アーティストの手癖や判断基準から開放され逸脱し，アーティストにも新たな視点を与えるだろう．


Keio SFC Nao Tokui Lab (Computational Creativity Lab) x-visual team

Credits:
- Scott Allen
- **Yusuke Yamada**
- Reo Anzai
- Santa Naruse
- Aina Ono
